#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
test.py â€• Kakao-chat Qdrant ê²€ìƒ‰ ì˜ˆì œ
"""

import json
import os
import warnings
from typing import List

import openai
from dotenv import load_dotenv
from qdrant_client import QdrantClient
from qdrant_client.models import VectorParams, Distance

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • ë° ì¤€ë¹„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
warnings.filterwarnings("ignore", category=DeprecationWarning)

load_dotenv()  # .env ë¡œë“œ
openai.api_key = os.getenv("OPENAI_API_KEY")

# â˜… .env ê°’ ì½ê¸° (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
QDRANT_HOST = "localhost"   # docker ë‚´ë¶€ë©´ 'qdrant'
QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))
QDRANT_API_KEY = os.getenv("X_API_KEY")                # â˜… ì¶”ê°€ëœ ë¶€ë¶„QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))
COLLECTION   = "kakao-chat"
MODEL        = "text-embedding-3-small"
VECTOR_DIM   = 1536  # text-embedding-3-small ê¸°ì¤€

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—¬í¼ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ensure_collection(client: QdrantClient, name: str, dim: int) -> None:
    """ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ í•„ìš” íŒŒë¼ë¯¸í„°ë¡œ ìƒì„±í•œë‹¤."""
    existing = [c.name for c in client.get_collections().collections]
    if name in existing:
        return

    print(f"ğŸ“ ì»¬ë ‰ì…˜ '{name}' ì—†ìŒ â†’ ìƒˆë¡œ ìƒì„±(dim={dim})")
    client.recreate_collection(
        collection_name=name,
        vectors_config=VectorParams(size=dim, distance=Distance.COSINE),
    )

def embed(texts: List[str]) -> List[List[float]]:
    """OpenAI ì„ë² ë”© í˜¸ì¶œ(Batch 96)."""
    BATCH = 96
    vectors = []
    for i in range(0, len(texts), BATCH):
        resp = openai.embeddings.create(model=MODEL, input=texts[i : i + BATCH])
        vectors.extend([d.embedding for d in resp.data])
    return vectors

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ ë¡œì§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main() -> None:
    query_text = "ì‚¬ë‘í•´"

    # 1) ì„ë² ë”©
    embedding = embed([query_text])[0]
    print(f"âœ… ì„ë² ë”© ì™„ë£Œ (dim={len(embedding)})")

    # 2) Qdrant ì—°ê²°
    client = QdrantClient(
        host=QDRANT_HOST,
        port=QDRANT_PORT,
        https=False,
        api_key=os.getenv("X_API_KEY"),  # â† API í‚¤ ì¶”ê°€!
        timeout=30.0,
    )
    ensure_collection(client, COLLECTION, len(embedding))

    # 3) ì°¨ì› ê²€ì¦
    info = client.get_collection(COLLECTION)
    dim_qdrant = info.config.params.vectors.size
    if dim_qdrant != len(embedding):
        raise ValueError(
            f"ë²¡í„° ì°¨ì› ë¶ˆì¼ì¹˜: OpenAI={len(embedding)} vs Qdrant={dim_qdrant}"
        )

    # 4) ê²€ìƒ‰
    hits = client.search(
        collection_name=COLLECTION,
        query_vector=embedding,
        limit=6,
        with_payload=True,
    )

    # 5) ê²°ê³¼ ì¶œë ¥
    print("\nğŸ” Top-5 ê²°ê³¼ ------------------------------")
    for idx, h in enumerate(hits, 1):
        print(
            json.dumps(
                {
                    "rank": idx,
                    "score": round(h.score, 4),
                    "content": h.payload.get("content", "")[:120],
                    "query_sender": h.payload.get("query_sender"),
                    "response_sender": h.payload.get("response_sender"),
                },
                ensure_ascii=False,
                indent=2,
            )
        )

if __name__ == "__main__":
    main()
